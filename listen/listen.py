import speech_recognition as sr
import queue
import time
import threading

from utility.debug import *

###################################################
import wave
from funasr import AutoModel

# ðŸ”¹ è¨­å®š FunASR æ¨¡åž‹è®Šæ•¸
ASR_MODEL = "paraformer-zh"  # èªžéŸ³è­˜åˆ¥æ¨¡åž‹
VAD_MODEL = "fsmn-vad"       # èªžéŸ³æ´»å‹•æª¢æ¸¬ï¼ˆå¯é¸ï¼‰
PUNC_MODEL = "ct-punc"       # æ¨™é»žç¬¦è™Ÿæ¨¡åž‹ï¼ˆå¯é¸ï¼‰

def save_audio(audio_data, filename="temp.wav"):
    """å°‡ SpeechRecognition éŒ„è£½çš„éŸ³è¨Šå­˜ç‚º WAV æª”æ¡ˆ"""
    with wave.open(filename, "wb") as wf:
        wf.setnchannels(1)  # å–®è²é“
        wf.setsampwidth(2)  # 16-bit PCM
        wf.setframerate(16000)  # 16kHz å–æ¨£çŽ‡
        wf.writeframes(audio_data.get_wav_data(convert_rate=16000))
###################################################

class Listen:
    HOTWORDS = ["hey assistant", "hi mark", "hey mark", "ok google", "hi ducky"]
    SILENCE_TIMEOUT = 20  # è‹¥è¶…éŽ n ç§’æ²’åµæ¸¬åˆ°èªžéŸ³ï¼Œå‰‡å›žåˆ° Hotword åµæ¸¬æ¨¡å¼
    def __init__(self, device_index = 0):
        self.device_index = device_index
        self.listen_queue = queue.Queue()
        self.flag_run = False
        self.service_thread = None
        self.is_waiting = False

        self.last_speech_time = time.time()  # è¨˜éŒ„æœ€å¾Œä¸€æ¬¡è¾¨è­˜æˆåŠŸçš„æ™‚é–“

        self.recognizer = None
        self.microphone = None

        # self.model = AutoModel(model=ASR_MODEL, vad_model=VAD_MODEL, punc_model=PUNC_MODEL, disable_update=True, disable_log=True, disable_pbar=True)
        self.model = None

    def wait(self):
        self.last_speech_time = time.time()

    def get(self):
        # print(f"Listen Queue: {self.listen_queue.qsize()}, {self.listen_queue.empty()}")
        if not self.listen_queue.empty():
            return self.listen_queue.get()
        else:
            return None

    def list_dev(self):
        for index, name in enumerate(s_r.Microphone.list_microphone_names()):
            dbg_info("Microphone with name \"{1}\" found for `Microphone(device_index={0})`".format(index, name))

    def start(self):
        self.model = AutoModel(model=ASR_MODEL, vad_model=VAD_MODEL, punc_model=PUNC_MODEL, disable_update=True, disable_log=True, disable_pbar=True)
        
        self.service_thread = threading.Thread(target=self.__service, daemon=True)
        self.service_thread.start()

    def __service(self):
        dbg_info("Listen Module Service thread start")
        self.flag_run = True

        # init sr
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone(device_index=self.device_index)
        """ä¸»è¿´åœˆï¼ŒæŒçºŒç­‰å¾…å–šé†’è©žä¸¦é€²å…¥èªžéŸ³æ¨¡å¼"""
        while self.flag_run:
            if self.listen_for_hotword():
                self.listen_for_speech()
        dbg_info("Listen Module Service thread end")

    def listen_for_hotword(self):
        """Listen for a wake word from the list of HOTWORDS"""
        # recognizer = sr.Recognizer()
        # mic = sr.Microphone(device_index=device_index)

        with self.microphone as source:
            dbg_info(f"Waiting for hotword")
            self.recognizer.adjust_for_ambient_noise(source)

            while True:
                try:
                    audio = self.recognizer.listen(source)
                    text = self.recognizer.recognize_google(audio).lower()
                    dbg_trace(f"Recognized: {text}")

                    # âœ… Check if any hotword is detected
                    if any(word in text for word in self.HOTWORDS):
                        dbg_info("âœ… Hotword detected! Activating assistant...")
                        return text
                except sr.UnknownValueError:
                    pass  # No speech detected, continue listening
                except sr.RequestError:
                    dbg_error("âŒ Speech recognition service error")
                    return False


    def listen_for_speech(self):
        """åœ¨ Hotword è¢«è§¸ç™¼å¾Œï¼Œé–‹å§‹æŒçºŒç›£è½èªžéŸ³"""
        # recognizer = sr.Recognizer()
        # mic = sr.Microphone(device_index=device_index)

        self.last_speech_time = time.time()  # è¨˜éŒ„æœ€å¾Œä¸€æ¬¡è¾¨è­˜æˆåŠŸçš„æ™‚é–“

        with self.microphone as source:
            self.recognizer.adjust_for_ambient_noise(source)  # é™ä½ŽèƒŒæ™¯é›œéŸ³
            dbg_info("ðŸ”Š Enter listen mode, please speak...")

            while True:
                try:
                    # audio = self.recognizer.listen(source, timeout=3)  # é™åˆ¶éŒ„éŸ³æ™‚é–“
                    audio = self.recognizer.listen(source, phrase_time_limit=10)  # é™åˆ¶éŒ„éŸ³æ™‚é–“

                    # å­˜å„²éŒ„è£½çš„éŸ³è¨Š
                    save_audio(audio, "temp.wav")

                    # ä½¿ç”¨ FunASR é€²è¡ŒèªžéŸ³è¾¨è­˜
                    result = self.model.generate("temp.wav")
                    # å¦‚æžœæˆåŠŸè¾¨è­˜åˆ°èªžéŸ³
                    text = result[0]['text']

                    # text = self.recognizer.recognize_google(audio).lower()

                    # å¦‚æžœæˆåŠŸè¾¨è­˜åˆ°èªžéŸ³
                    if text:
                        dbg_trace(f"ðŸ“ Result: {text}")
                        self.listen_queue.put(text)  # æ”¾å…¥ queue
                        self.last_speech_time = time.time()  # æ›´æ–°æ™‚é–“

                except sr.UnknownValueError:
                    pass  # æ²’æœ‰åµæ¸¬åˆ°å¯è¾¨è­˜çš„èªžéŸ³
                except sr.WaitTimeoutError:
                    pass  # è‹¥ 3 ç§’å…§æ²’è²éŸ³ï¼Œç¹¼çºŒç›£è½
                except sr.RequestError:
                    dbg_error("âŒ Service error")
                    return

                # å¦‚æžœè¶…éŽ SILENCE_TIMEOUT ç§’æ²’æœ‰èªžéŸ³è¼¸å…¥ï¼Œå‰‡è¿”å›ž hotword åµæ¸¬æ¨¡å¼
                if time.time() - self.last_speech_time > self.SILENCE_TIMEOUT and self.listen_queue.empty():
                    dbg_info("ðŸ›‘ listen tiemout, go back to hot word mode...")
                    return
